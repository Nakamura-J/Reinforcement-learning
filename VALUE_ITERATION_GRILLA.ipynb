{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "jSuaEYod6dcH"
      },
      "source": [
        "import numpy as np #Para trabajar con arreglos"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Kt1pGIIE6dcR"
      },
      "source": [
        "# Construcción de grilla\n",
        "\n",
        "class Mapa:\n",
        "\n",
        "    def __init__(self,ancho,alto,inicio):\n",
        "        self.ancho = ancho\n",
        "        self.alto = alto\n",
        "        self.fila = inicio[0]\n",
        "        self.columna = inicio[1]\n",
        "\n",
        "    def conjunto(self,recompensas,acciones):\n",
        "        self.recompensas = recompensas # diccionario de posibles recompensas para cada estado (fila,columna) : r\n",
        "        self.acciones = acciones # diccionario de posibles acciones para cada estado (fila,columna) : ('U','D','L','R')\n",
        "\n",
        "    def fijar_estado(self,s):\n",
        "        self.fila = s[0]\n",
        "        self.columna = s[1]\n",
        "\n",
        "    def estado_actual(self):\n",
        "        return (self.fila,self.columna)\n",
        "\n",
        "    def es_final(self,s):\n",
        "        return s not in self.acciones\n",
        "\n",
        "    def mover(self,accion):\n",
        "        if accion in self.acciones[self.estado_actual()] :\n",
        "            if accion == 'U':\n",
        "                self.fila -= 1\n",
        "            elif accion == 'D':\n",
        "                self.fila += 1\n",
        "            elif accion == 'L':\n",
        "                self.columna -= 1\n",
        "            elif accion == 'R':\n",
        "                self.columna += 1\n",
        "        return self.recompensas.get(self.estado_actual(),0)\n",
        "\n",
        "    def deshacer(self,accion):\n",
        "        if accion in self.acciones[self.estado_actual()] :\n",
        "            if accion == 'U':\n",
        "                self.fila += 1\n",
        "            elif accion == 'D':\n",
        "                self.fila -= 1\n",
        "            elif accion == 'L':\n",
        "                self.columna += 1\n",
        "            elif accion == 'R':\n",
        "                self.columna -= 1\n",
        "        assert(self.estado_actual() in self.todos_estados())\n",
        "\n",
        "    def fin(self):\n",
        "        return self.estado_actual not in self.acciones\n",
        "\n",
        "    def todos_estados(self):\n",
        "        return set(list(self.acciones.keys()) + list(self.recompensas.keys()))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "mkVqC0ca6dcV"
      },
      "source": [
        "#CONFIGURACIÓN DEL PROBLEMA\n",
        "# Definición de la función mapa_con_costo con costo por defecto de -0.1\n",
        "def mapa_con_costo(costo_paso = -0.1):\n",
        "    # Crea un objeto Mapa de 4 columnas (ancho), 3 filas (alto) y estado inicial en (2,0)\n",
        "    g = Mapa(4,3,(2,0))\n",
        "    # Define las recompensas fijas: +1 en (0,3) y -1 en (1,3)\n",
        "    recompensas = {(0,3) : 1, (1,3):-1}\n",
        "    # Diccionario que define las acciones posibles desde cada celda del mapa\n",
        "    acciones = {\n",
        "        (0,0) : ('D','R'),       # desde (0,0) se puede mover abajo o derecha\n",
        "        (0,1) : ('L','R'),       # desde (0,1) se puede mover izquierda o derecha\n",
        "        (0,2) : ('L','R','D'),   # desde (0,2) se puede mover izq, der o abajo\n",
        "#        (0,3) : ('',),          # (comentado) sin acciones desde celda terminal (0,3)\n",
        "        (1,0) : ('U','D'),       # desde (1,0) se puede mover arriba o abajo\n",
        "#        (1,1) : ('',),          # (comentado) celda bloqueada (pared)\n",
        "        (1,2) : ('U','D','R'),   # desde (1,2) se puede mover arriba, abajo o derecha\n",
        "#        (1,3) : ('',),          # (comentado) sin acciones desde celda terminal (1,3)\n",
        "        (2,0) : ('U','R'),       # desde (2,0) se puede mover arriba o derecha\n",
        "        (2,1) : ('L','R'),       # desde (2,1) se puede mover izquierda o derecha\n",
        "        (2,2) : ('U','L','R'),   # desde (2,2) se puede mover arriba, izquierda o derecha\n",
        "        (2,3) : ('L','U')        # desde (2,3) se puede mover izquierda o arriba\n",
        "        }\n",
        "    # Asigna las recompensas y acciones iniciales al mapa\n",
        "    g.conjunto(recompensas,acciones)\n",
        "    # Reinicia recompensas como diccionario vacío\n",
        "    recompensas = {}\n",
        "    # Recorre todas las celdas del mapa por filas y columnas\n",
        "    for fila in range(g.alto):\n",
        "        for columna in range(g.ancho):\n",
        "            # Asigna costo de paso (negativo) a todas las celdas\n",
        "            recompensas[(fila,columna)] = costo_paso\n",
        "    # Vuelve a asignar +1 en (0,3)\n",
        "    recompensas[(0,3)] = 1\n",
        "    # Vuelve a asignar -1 en (1,3)\n",
        "    recompensas[(1,3)] = -1\n",
        "    # Elimina la celda (1,1) de las recompensas (pared o inaccesible)\n",
        "    recompensas.pop((1,1),None)\n",
        "    # Actualiza el mapa con las recompensas de costo de paso y mismas acciones\n",
        "    g.conjunto(recompensas,g.acciones)\n",
        "    # Retorna el objeto mapa configurado\n",
        "    return g\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "DQmGuKnr6dcW"
      },
      "source": [
        "#Mostrar valores def mostrar_valores(V,g):\n",
        "# Función para mostrar los valores de cada celda en el mapa\n",
        "def mostrar_valores(V,g):\n",
        "    # Recorre las filas del mapa\n",
        "    for fila in range(g.alto):\n",
        "        # Imprime una línea de separación\n",
        "        print(20*\"-\")\n",
        "        # Recorre las columnas del mapa\n",
        "        for columna in range(g.ancho):\n",
        "            # Obtiene el valor V de la celda (fila,columna), 0 si no existe\n",
        "            v = V.get((fila,columna),0)\n",
        "\n",
        "            # Imprime el valor con dos decimales en la celda\n",
        "            print(\" %.2f|\" % v, end=\"\")\n",
        "        # Salto de línea al terminar la fila\n",
        "        print(\"\")\n",
        "\n",
        "# Función para mostrar la política (acciones) de cada celda en el mapa\n",
        "def mostrar_politica(P,g) :\n",
        "    # Recorre las filas del mapa\n",
        "    for fila in range(g.alto):\n",
        "        # Imprime una línea de separación\n",
        "        print(20*\"-\")\n",
        "        # Recorre las columnas del mapa\n",
        "        for columna in range(g.ancho):\n",
        "            # Obtiene la acción asignada en la celda (fila,columna), vacío si no existe\n",
        "            a = P.get((fila,columna),'')\n",
        "            # Imprime la acción en la celda\n",
        "            print(\" %s |\" % a, end=\"\")\n",
        "        # Salto de línea al terminar la fila\n",
        "        print(\"\")\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsSNPU2A6dcX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8bb2c3d-ad7d-40d1-e80d-34da4c072093"
      },
      "source": [
        "# Número máximo de repeticiones de la iteración de valores\n",
        "repeticiones = 20\n",
        "# Contador de iteraciones\n",
        "iteraciones = 0\n",
        "# Factor de descuento (pondera el futuro)\n",
        "gamma = 0.9\n",
        "# Umbral de convergencia (tolerancia de error)\n",
        "epsilon = 1e-3\n",
        "# Conjunto de acciones posibles\n",
        "total_acciones = ('U','D','L','R')\n",
        "# Crea el mapa con costo de paso\n",
        "mapa = mapa_con_costo()\n",
        "# Obtiene todos los estados posibles del mapa\n",
        "estados = mapa.todos_estados()\n",
        "# Inicializa diccionario de valores\n",
        "V = {}\n",
        "# Asigna valor inicial 0.0 a todos los estados\n",
        "for s in estados:\n",
        "    V[s] = 0.0\n",
        "\n",
        "# Bucle principal de Iteración de Valores\n",
        "while True:\n",
        "    # Reinicia delta (cambio máximo en valores)\n",
        "    delta = 0\n",
        "    # Incrementa el contador de iteraciones\n",
        "    iteraciones += 1\n",
        "    # Recorre todos los estados del mapa\n",
        "    for s in estados:\n",
        "        # Si el estado no tiene acciones (terminal o pared), lo salta\n",
        "        if s not in mapa.acciones.keys():\n",
        "            continue\n",
        "        # Guarda el valor anterior del estado\n",
        "        v = V[s]\n",
        "        # Inicializa el máximo valor posible como -infinito\n",
        "        max_val = float(\"-inf\")\n",
        "        # Evalúa cada acción posible en ese estado\n",
        "        for accion in mapa.acciones[s]:\n",
        "            # Coloca el mapa en el estado actual\n",
        "            mapa.fijar_estado(s)\n",
        "            # Ejecuta la acción y obtiene la recompensa\n",
        "            r = mapa.mover(accion)\n",
        "            # Calcula el valor: recompensa + valor futuro descontado\n",
        "            val = r + gamma * V[mapa.estado_actual()]  # determinístico\n",
        "            # Si este valor es mejor que el máximo actual, lo actualiza\n",
        "            if val > max_val:\n",
        "                max_val = val\n",
        "        # Actualiza el valor del estado con el máximo valor hallado\n",
        "        V[s] = max_val\n",
        "        # Calcula la diferencia máxima entre valores viejos y nuevos\n",
        "        delta = max(delta,abs(v-V[s]))\n",
        "\n",
        "    # Condición de parada: convergencia (delta < epsilon) o repeticiones máximas\n",
        "    if delta < epsilon or iteraciones >= repeticiones:\n",
        "        # Muestra la tabla de valores finales\n",
        "        mostrar_valores(V,mapa)\n",
        "        # Termina el bucle\n",
        "        break\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------\n",
            " 0.62| 0.80| 1.00| 0.00|\n",
            "--------------------\n",
            " 0.46| 0.00| 0.80| 0.00|\n",
            "--------------------\n",
            " 0.31| 0.46| 0.62| 0.46|\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIXNvrT26dcZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72c275ae-36b3-4d8e-c734-8bb5bb6781f7"
      },
      "source": [
        "# Diccionario para guardar la política (mejor acción por estado)\n",
        "pi = {}\n",
        "# Recorre todos los estados que tienen acciones posibles\n",
        "for s in mapa.acciones.keys():\n",
        "    # Inicializa el mejor valor como -infinito\n",
        "    max_val = float(\"-inf\")\n",
        "    # Recorre todas las acciones posibles en el estado s\n",
        "    for accion in mapa.acciones[s]:\n",
        "        # Fija el estado actual en el mapa\n",
        "        mapa.fijar_estado(s)\n",
        "        # Ejecuta la acción y obtiene la recompensa inmediata\n",
        "        r = mapa.mover(accion)\n",
        "        # Calcula el valor: recompensa + valor del siguiente estado (greedy sin descuento aquí)\n",
        "        val = r + V[mapa.estado_actual()]\n",
        "        # Si este valor es mejor que el actual máximo, actualiza el máximo y la acción\n",
        "        if val > max_val :\n",
        "            max_val = val\n",
        "            max_accion = accion\n",
        "    # Asigna la mejor acción encontrada al estado en la política\n",
        "    pi[s] = max_accion\n",
        "\n",
        "# Muestra la política obtenida en formato de tabla\n",
        "mostrar_politica(pi,mapa)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------\n",
            " R | R | R |  |\n",
            "--------------------\n",
            " U |  | U |  |\n",
            "--------------------\n",
            " U | R | U | L |\n"
          ]
        }
      ]
    }
  ]
}